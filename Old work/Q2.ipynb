{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1537,1540,1542,1561,1575,1606,1614,1615,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2013_14_PP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>OPEID</th>\n",
       "      <th>OPEID6</th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>ACCREDAGENCY</th>\n",
       "      <th>INSTURL</th>\n",
       "      <th>NPCURL</th>\n",
       "      <th>...</th>\n",
       "      <th>D100_L4</th>\n",
       "      <th>TRANS_4</th>\n",
       "      <th>DTRANS_4</th>\n",
       "      <th>TRANS_L4</th>\n",
       "      <th>DTRANS_L4</th>\n",
       "      <th>ICLEVEL</th>\n",
       "      <th>UGDS_MEN</th>\n",
       "      <th>UGDS_WOMEN</th>\n",
       "      <th>CDR3_DENOM</th>\n",
       "      <th>CDR2_DENOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>100200</td>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>35762</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2234</td>\n",
       "      <td>882.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4861</td>\n",
       "      <td>0.5139</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100663</td>\n",
       "      <td>105200</td>\n",
       "      <td>1052</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>35294-0110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2358</td>\n",
       "      <td>1378.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>0.5865</td>\n",
       "      <td>3475.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100690</td>\n",
       "      <td>2503400</td>\n",
       "      <td>25034</td>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36117-3553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3913</td>\n",
       "      <td>0.6087</td>\n",
       "      <td>336.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100706</td>\n",
       "      <td>105500</td>\n",
       "      <td>1055</td>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>35899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3136</td>\n",
       "      <td>759.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5580</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>1392.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100724</td>\n",
       "      <td>100500</td>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36104-0271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4085</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1743 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNITID    OPEID  OPEID6                               INSTNM        CITY  \\\n",
       "0  100654   100200    1002             Alabama A & M University      Normal   \n",
       "1  100663   105200    1052  University of Alabama at Birmingham  Birmingham   \n",
       "2  100690  2503400   25034                   Amridge University  Montgomery   \n",
       "3  100706   105500    1055  University of Alabama in Huntsville  Huntsville   \n",
       "4  100724   100500    1005             Alabama State University  Montgomery   \n",
       "\n",
       "  STABBR         ZIP  ACCREDAGENCY  INSTURL  NPCURL     ...      D100_L4  \\\n",
       "0     AL       35762           NaN      NaN     NaN     ...          NaN   \n",
       "1     AL  35294-0110           NaN      NaN     NaN     ...          NaN   \n",
       "2     AL  36117-3553           NaN      NaN     NaN     ...          NaN   \n",
       "3     AL       35899           NaN      NaN     NaN     ...          NaN   \n",
       "4     AL  36104-0271           NaN      NaN     NaN     ...          NaN   \n",
       "\n",
       "   TRANS_4  DTRANS_4  TRANS_L4  DTRANS_L4  ICLEVEL  UGDS_MEN  UGDS_WOMEN  \\\n",
       "0   0.2234     882.0       NaN        NaN        1    0.4861      0.5139   \n",
       "1   0.2358    1378.0       NaN        NaN        1    0.4135      0.5865   \n",
       "2   0.0000       3.0       NaN        NaN        1    0.3913      0.6087   \n",
       "3   0.3136     759.0       NaN        NaN        1    0.5580      0.4420   \n",
       "4   0.0000    1351.0       NaN        NaN        1    0.4085      0.5915   \n",
       "\n",
       "   CDR3_DENOM  CDR2_DENOM  \n",
       "0      1573.0         NaN  \n",
       "1      3475.0         NaN  \n",
       "2       336.0         NaN  \n",
       "3      1392.0         NaN  \n",
       "4      1960.0         NaN  \n",
       "\n",
       "[5 rows x 1743 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 1, 4, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PREDDEG'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1383/1383 [00:00<00:00, 2894.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097.0209396460527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Q1 Average SAT score ==========================================\n",
    "\n",
    "df_4y = df[df['HIGHDEG'] >= 3]\n",
    "df_4y = df_4y[df_4y['PREDDEG'] != 4]\n",
    "df_4y = df_4y.ix[:][['UGDS','SAT_AVG']]\n",
    "df_4y = df_4y.dropna()\n",
    "\n",
    "total_students = 0\n",
    "total_SAT_score = 0\n",
    "\n",
    "for i in tqdm.tqdm(df_4y.index):\n",
    "    total_students += int(df_4y.ix[i]['UGDS']/4)\n",
    "    total_SAT_score += int(df_4y.ix[i]['SAT_AVG'])*int(df_4y.ix[i]['UGDS']/4)\n",
    "\n",
    "print (total_SAT_score/total_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENRL_ORIG_YR2_RT</th>\n",
       "      <th>SAT_AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENRL_ORIG_YR2_RT</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.661837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAT_AVG</th>\n",
       "      <td>0.661837</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ENRL_ORIG_YR2_RT   SAT_AVG\n",
       "ENRL_ORIG_YR2_RT          1.000000  0.661837\n",
       "SAT_AVG                   0.661837  1.000000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2 SAT vs 2 year enrollment ==========================================\n",
    "\n",
    "df2 = df.ix[:][['ENRL_ORIG_YR2_RT','SAT_AVG']]\n",
    "df2['ENRL_ORIG_YR2_RT'] = pd.to_numeric(df2['ENRL_ORIG_YR2_RT'], errors='coerce')\n",
    "df2 = df2.dropna()\n",
    "df2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13734663453323226"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2 income and completion ==========================================\n",
    "df3 = df.ix[:][['LO_INC_COMP_ORIG_YR4_RT','MD_INC_COMP_ORIG_YR4_RT','HI_INC_COMP_ORIG_YR4_RT']]\n",
    "df3['LO_INC_COMP_ORIG_YR4_RT'] = pd.to_numeric(df3['LO_INC_COMP_ORIG_YR4_RT'], errors='coerce')\n",
    "df3['MD_INC_COMP_ORIG_YR4_RT'] = pd.to_numeric(df3['MD_INC_COMP_ORIG_YR4_RT'], errors='coerce')\n",
    "df3['HI_INC_COMP_ORIG_YR4_RT'] = pd.to_numeric(df3['HI_INC_COMP_ORIG_YR4_RT'], errors='coerce')\n",
    "df3 = df3.dropna()\n",
    "\n",
    "df3['HI_INC_COMP_ORIG_YR4_RT'].mean() - df3['LO_INC_COMP_ORIG_YR4_RT'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-204.36381326489089"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4 t-test ==========================================\n",
    "from scipy.stats import ttest_ind\n",
    "t, p = ttest_ind(np.array(df3['HI_INC_COMP_ORIG_YR4_RT']), np.array(df3['LO_INC_COMP_ORIG_YR4_RT']), equal_var=True)\n",
    "np.log10(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23349999999999999"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5 Ethnicity ==========================================\n",
    "df5 = df.ix[:][['UGDS_WHITE',\n",
    "'UGDS_BLACK',\n",
    "'UGDS_HISP',\n",
    "'UGDS_ASIAN',\n",
    "'UGDS_AIAN',\n",
    "'UGDS_NHPI',\n",
    "'UGDS_2MOR',\n",
    "'UGDS_NRA',\n",
    "'UGDS_UNKN']]\n",
    "df5 = df5.dropna()\n",
    "\n",
    "def get_max(df5):\n",
    "    max_val = max([df5['UGDS_WHITE'],df5['UGDS_BLACK'],df5['UGDS_HISP'],df5['UGDS_ASIAN'],\n",
    "                  df5['UGDS_AIAN'],df5['UGDS_NHPI'],df5['UGDS_2MOR'],df5['UGDS_NRA'],\n",
    "                  df5['UGDS_UNKN']])\n",
    "    return (max_val)\n",
    "\n",
    "def get_min(df5):\n",
    "    min_val = min([df5['UGDS_WHITE'],df5['UGDS_BLACK'],df5['UGDS_HISP'],df5['UGDS_ASIAN'],\n",
    "                  df5['UGDS_AIAN'],df5['UGDS_NHPI'],df5['UGDS_2MOR'],df5['UGDS_NRA'],\n",
    "                  df5['UGDS_UNKN']])\n",
    "    return (min_val)\n",
    "\n",
    "df5['max'] = df5.apply(get_max, axis=1)\n",
    "df5['min'] = df5.apply(get_min, axis=1)\n",
    "df5['diff'] = df5['max'] - df5['min']\n",
    "df5 = df5[df5['diff'] > 0]\n",
    "df5['diff'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Normal\n",
       "1             Birmingham\n",
       "2             Montgomery\n",
       "3             Huntsville\n",
       "4             Montgomery\n",
       "5             Tuscaloosa\n",
       "6         Alexander City\n",
       "7                 Athens\n",
       "8             Montgomery\n",
       "9                 Auburn\n",
       "10            Birmingham\n",
       "11           Phenix City\n",
       "12                 Selma\n",
       "13            Montgomery\n",
       "14            Enterprise\n",
       "15           Bay Minette\n",
       "16            Montgomery\n",
       "17               Gadsden\n",
       "18           Albertville\n",
       "19                Dothan\n",
       "20            Hanceville\n",
       "21                 Selma\n",
       "22            Birmingham\n",
       "23            Montgomery\n",
       "24              Florence\n",
       "25            Huntsville\n",
       "26          Jacksonville\n",
       "27               Brewton\n",
       "28            Birmingham\n",
       "29                Tanner\n",
       "              ...       \n",
       "7774             Houston\n",
       "7775             Houston\n",
       "7776               Plano\n",
       "7777          Cedar Hill\n",
       "7778              Dallas\n",
       "7779         San Antonio\n",
       "7780            Stafford\n",
       "7781             Fremont\n",
       "7782          Sacramento\n",
       "7783           McClellan\n",
       "7784          Sacramento\n",
       "7785          Sacramento\n",
       "7786              Merced\n",
       "7787             El Paso\n",
       "7788              Austin\n",
       "7789          Emeryville\n",
       "7790         Bloomington\n",
       "7791          Schaumburg\n",
       "7792       Downers Grove\n",
       "7793              Aurora\n",
       "7794       Overland Park\n",
       "7795    Highland Heights\n",
       "7796           Brentwood\n",
       "7797            Martinez\n",
       "7798            Fairburn\n",
       "7799            Columbus\n",
       "7800            Valdosta\n",
       "7801       Warner Robins\n",
       "7802       Milledgeville\n",
       "7803      Stone Mountain\n",
       "Name: CITY, dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'UGDS_WOMEN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1,6,442,451,598,607,611,620,624,633,789,802,806,815,893,906,971,984,997,1153,1166,1407,1408,1411,1425,1431,1432,1433,1437,1438,1439,1440,1445,1446,1447,1451,1452,1453,1454,1459,1460,1461,1465,1466,1467,1468,1473,1474,1475,1479,1480,1481,1482,1487,1488,1489,1501,1502,1537,1538,1539,1540,1541,1542,1603,1606,1609,1610,1611,1613,1614,1615,1616,1688,1689,1690,1691,1692,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1,6,1408,1431,1432,1433,1475,1489,1537,1538,1539,1540,1542,1603,1606,1610,1611,1614,1615,1616,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1,1447,1537,1540,1542,1606,1614,1615) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1,1537,1540,1542,1606,1614,1615) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1,6,1461,1561,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Q6 Women ==========================================\n",
    "\n",
    "df01 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2001_02_PP.csv')\n",
    "df02 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2002_03_PP.csv')\n",
    "df03 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2003_04_PP.csv')\n",
    "df04 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2004_05_PP.csv')\n",
    "df05 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2005_06_PP.csv')\n",
    "df06 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2006_07_PP.csv')\n",
    "df07 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2007_08_PP.csv')\n",
    "df08 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2008_09_PP.csv')\n",
    "df09 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2009_10_PP.csv')\n",
    "df10 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2010_11_PP.csv')\n",
    "\n",
    "df01 = df01.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df02 = df02.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df03 = df03.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df04 = df04.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df05 = df05.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df06 = df06.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df07 = df07.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df08 = df08.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df09 = df09.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df10 = df10.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "\n",
    "df01 = df01.dropna()\n",
    "df02 = df02.dropna()\n",
    "df03 = df03.dropna()\n",
    "df04 = df04.dropna()\n",
    "df05 = df05.dropna()\n",
    "df06 = df06.dropna()\n",
    "df07 = df07.dropna()\n",
    "df08 = df08.dropna()\n",
    "df09 = df09.dropna()\n",
    "df10 = df10.dropna()\n",
    "\n",
    "schools = set(df01['UNITID'].unique())\n",
    "schools = schools.intersection(set(df02['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df03['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df04['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df05['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df06['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df07['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df08['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df09['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df10['UNITID'].unique()))\n",
    "\n",
    "df01 = df01[df01['UNITID'].isin(schools)]\n",
    "df02 = df02[df02['UNITID'].isin(schools)]\n",
    "df03 = df03[df03['UNITID'].isin(schools)]\n",
    "df04 = df04[df04['UNITID'].isin(schools)]\n",
    "df05 = df05[df05['UNITID'].isin(schools)]\n",
    "df06 = df06[df06['UNITID'].isin(schools)]\n",
    "df07 = df07[df07['UNITID'].isin(schools)]\n",
    "df08 = df08[df08['UNITID'].isin(schools)]\n",
    "df09 = df09[df09['UNITID'].isin(schools)]\n",
    "df10 = df10[df10['UNITID'].isin(schools)]\n",
    "\n",
    "df01['NUM_WOMEN'] = df01['UGDS_WOMEN']*df01['UGDS']\n",
    "df02['NUM_WOMEN'] = df02['UGDS_WOMEN']*df02['UGDS']\n",
    "df03['NUM_WOMEN'] = df03['UGDS_WOMEN']*df03['UGDS']\n",
    "df04['NUM_WOMEN'] = df04['UGDS_WOMEN']*df04['UGDS']\n",
    "df05['NUM_WOMEN'] = df05['UGDS_WOMEN']*df05['UGDS']\n",
    "df06['NUM_WOMEN'] = df06['UGDS_WOMEN']*df06['UGDS']\n",
    "df07['NUM_WOMEN'] = df07['UGDS_WOMEN']*df07['UGDS']\n",
    "df08['NUM_WOMEN'] = df08['UGDS_WOMEN']*df08['UGDS']\n",
    "df09['NUM_WOMEN'] = df09['UGDS_WOMEN']*df09['UGDS']\n",
    "df10['NUM_WOMEN'] = df10['UGDS_WOMEN']*df10['UGDS']\n",
    "\n",
    "total_women = df01['NUM_WOMEN'].sum() + df04['NUM_WOMEN'].sum() + df07['NUM_WOMEN'].sum() + df09['NUM_WOMEN'].sum() +df02['NUM_WOMEN'].sum() + df05['NUM_WOMEN'].sum() + df08['NUM_WOMEN'].sum() + df10['NUM_WOMEN'].sum() + df03['NUM_WOMEN'].sum() + df06['NUM_WOMEN'].sum()\n",
    "total_stud =  df01['UGDS'].sum() + df04['UGDS'].sum() + df07['UGDS'].sum() + df09['UGDS'].sum() + df02['UGDS'].sum() + df05['UGDS'].sum() + df08['UGDS'].sum() + df10['UGDS'].sum() + df03['UGDS'].sum() + df06['UGDS'].sum() \n",
    "print (total_women/total_stud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df01['NUM_WOMEN'] = df01['UGDS_WOMEN']*df01['UGDS']\n",
    "df02['NUM_WOMEN'] = df02['UGDS_WOMEN']*df02['UGDS']\n",
    "df03['NUM_WOMEN'] = df03['UGDS_WOMEN']*df03['UGDS']\n",
    "df04['NUM_WOMEN'] = df04['UGDS_WOMEN']*df04['UGDS']\n",
    "df05['NUM_WOMEN'] = df05['UGDS_WOMEN']*df05['UGDS']\n",
    "df06['NUM_WOMEN'] = df06['UGDS_WOMEN']*df06['UGDS']\n",
    "df07['NUM_WOMEN'] = df07['UGDS_WOMEN']*df07['UGDS']\n",
    "df08['NUM_WOMEN'] = df08['UGDS_WOMEN']*df08['UGDS']\n",
    "df09['NUM_WOMEN'] = df09['UGDS_WOMEN']*df09['UGDS']\n",
    "df10['NUM_WOMEN'] = df10['UGDS_WOMEN']*df10['UGDS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5716597681583974\n"
     ]
    }
   ],
   "source": [
    "total_women = df01['NUM_WOMEN'].sum() + df04['NUM_WOMEN'].sum() + df07['NUM_WOMEN'].sum() + df09['NUM_WOMEN'].sum() +df02['NUM_WOMEN'].sum() + df05['NUM_WOMEN'].sum() + df08['NUM_WOMEN'].sum() + df10['NUM_WOMEN'].sum() + df03['NUM_WOMEN'].sum() + df06['NUM_WOMEN'].sum()\n",
    "total_stud =  df01['UGDS'].sum() + df04['UGDS'].sum() + df07['UGDS'].sum() + df09['UGDS'].sum() + df02['UGDS'].sum() + df05['UGDS'].sum() + df08['UGDS'].sum() + df10['UGDS'].sum() + df03['UGDS'].sum() + df06['UGDS'].sum() \n",
    "print (total_women/total_stud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df01 = df01.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df02 = df02.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df03 = df03.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df04 = df04.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df05 = df05.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df06 = df06.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df07 = df07.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df08 = df08.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df09 = df09.ix[:][['UNITID','UGDS_WOMEN','UGDS']]\n",
    "df10 = df10.ix[:][['UNITID','UGDS_WOMEN','UGDS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df01 = df01.dropna()\n",
    "df02 = df02.dropna()\n",
    "df03 = df03.dropna()\n",
    "df04 = df04.dropna()\n",
    "df05 = df05.dropna()\n",
    "df06 = df06.dropna()\n",
    "df07 = df07.dropna()\n",
    "df08 = df08.dropna()\n",
    "df09 = df09.dropna()\n",
    "df10 = df10.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5242"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schools = set(df01['UNITID'].unique())\n",
    "schools = schools.intersection(set(df02['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df03['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df04['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df05['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df06['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df07['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df08['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df09['UNITID'].unique()))\n",
    "schools = schools.intersection(set(df10['UNITID'].unique()))\n",
    "len(schools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df01 = df01[df01['UNITID'].isin(schools)]\n",
    "df02 = df02[df02['UNITID'].isin(schools)]\n",
    "df03 = df03[df03['UNITID'].isin(schools)]\n",
    "df04 = df04[df04['UNITID'].isin(schools)]\n",
    "df05 = df05[df05['UNITID'].isin(schools)]\n",
    "df06 = df06[df06['UNITID'].isin(schools)]\n",
    "df07 = df07[df07['UNITID'].isin(schools)]\n",
    "df08 = df08[df08['UNITID'].isin(schools)]\n",
    "df09 = df09[df09['UNITID'].isin(schools)]\n",
    "df10 = df10[df10['UNITID'].isin(schools)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6403539126287677\n"
     ]
    }
   ],
   "source": [
    "tot_avg = (df01['UGDS_WOMEN'].mean() + df05['UGDS_WOMEN'].mean() + df08['UGDS_WOMEN'].mean() + \n",
    "                df02['UGDS_WOMEN'].mean() + df06['UGDS_WOMEN'].mean() + df09['UGDS_WOMEN'].mean() + \n",
    "                df03['UGDS_WOMEN'].mean() + df07['UGDS_WOMEN'].mean() + df10['UGDS_WOMEN'].mean() + \n",
    "                df04['UGDS_WOMEN'].mean())/10\n",
    "print (tot_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewzhuang/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (6,9,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1411,1425,1427,1503,1517,1529,1530,1532,1537,1540,1541,1542,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1605,1606,1609,1610,1613,1614,1615,1725,1726,1727,1728,1729) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Q7 Regions ==========================================\n",
    "df15 = pd.read_csv('/Users/andrewzhuang/Downloads/CollegeScorecard_Raw_Data/MERGED2014_15_PP.csv')\n",
    "for i in df15['REGION'].unique():\n",
    "    cur_df = df15[df15['REGION'] == i]\n",
    "    print(len(cur_df[cur_df['LOCALE'] < 21])/len(cur_df))\n",
    "#Just look for the biggest printed out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44814814814814813\n",
      "0.3714036617262424\n",
      "0.5577797998180164\n",
      "0.5907429963459196\n",
      "0.4419306184012066\n",
      "0.5050505050505051\n",
      "0.3438914027149321\n",
      "0.3917089678510998\n",
      "0.0\n",
      "0.515527950310559\n"
     ]
    }
   ],
   "source": [
    "for i in df15['REGION'].unique():\n",
    "    cur_df = df15[df15['REGION'] == i]\n",
    "    print(len(cur_df[cur_df['LOCALE'] < 21])/len(cur_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
